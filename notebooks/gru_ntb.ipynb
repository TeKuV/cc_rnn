{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aaee8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, ticker=\"AMD\", years=4):\n",
    "        self.ticker = ticker\n",
    "        self.years = years\n",
    "        self.data = None\n",
    "\n",
    "    def fetch_data(self):\n",
    "        start_date = pd.Timestamp.today() - pd.DateOffset(years=self.years)\n",
    "        df = yf.download(self.ticker, start=start_date.strftime(\"%Y-%m-%d\"))\n",
    "        df = df[[\"Close\"]].dropna().reset_index()\n",
    "        df.columns = [\"Date\", \"Close\"]\n",
    "        self.data = df\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a554e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "\n",
    "\n",
    "class GRUPredictor:\n",
    "    def __init__(self, input_shape=None, model_path=None):\n",
    "        if model_path and os.path.exists(model_path):\n",
    "            self.model = load_model(model_path)\n",
    "        else:\n",
    "            self.model = Sequential()\n",
    "            self.model.add(\n",
    "                GRU(units=50, return_sequences=False, input_shape=input_shape)\n",
    "            )\n",
    "            self.model.add(Dense(1))\n",
    "            self.model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        return_history=False,\n",
    "        progress_callback=None,\n",
    "    ):\n",
    "        from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "        class StreamlitProgressCallback(Callback):\n",
    "            def __init__(self, total_epochs, bar):\n",
    "                self.total_epochs = total_epochs\n",
    "                self.bar = bar\n",
    "\n",
    "            def on_epoch_end(self, epoch, logs=None):\n",
    "                progress = int((epoch + 1) / self.total_epochs * 100)\n",
    "                self.bar.progress(\n",
    "                    progress,\n",
    "                    text=f\"Epoch {epoch+1}/{self.total_epochs} - Loss: {logs['loss']:.4f}\",\n",
    "                )\n",
    "\n",
    "        callbacks = []\n",
    "        if progress_callback:\n",
    "            callbacks.append(StreamlitProgressCallback(epochs, progress_callback))\n",
    "\n",
    "        history = self.model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=0,\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        return history if return_history else None\n",
    "\n",
    "    def predict_next_days(self, last_sequence, days=21):\n",
    "        predictions = []\n",
    "        current_sequence = last_sequence\n",
    "        for _ in range(days):\n",
    "            prediction = self.model.predict(\n",
    "                current_sequence.reshape(1, -1, 1), verbose=0\n",
    "            )\n",
    "            predictions.append(prediction[0, 0])\n",
    "            current_sequence = np.append(current_sequence[1:], prediction).reshape(\n",
    "                -1, 1\n",
    "            )\n",
    "        return np.array(predictions).reshape(-1, 1)\n",
    "\n",
    "    def save(self, path=\"./models/gru_model.keras\"):\n",
    "        self.model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367e96c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class GRUPreprocessor:\n",
    "    def __init__(self, sequence_length=60):\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def transform(self, data):\n",
    "        scaled = self.scaler.fit_transform(data[[\"Close\"]])\n",
    "        x, y = [], []\n",
    "        for i in range(self.sequence_length, len(scaled)):\n",
    "            x.append(scaled[i - self.sequence_length : i, 0])\n",
    "            y.append(scaled[i, 0])\n",
    "        return np.array(x), np.array(y), scaled\n",
    "\n",
    "    def reshape_input(self, x):\n",
    "        return x.reshape((x.shape[0], x.shape[1], 1))\n",
    "\n",
    "    def inverse_transform(self, values):\n",
    "        return self.scaler.inverse_transform(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from neuralprophet import NeuralProphet\n",
    "\n",
    "\n",
    "class NeuralProphetPredictor:\n",
    "    def __init__(self):\n",
    "        self.model = NeuralProphet()\n",
    "\n",
    "    def train_predict(self, df, future_days=21):\n",
    "        df_prophet = df.rename(columns={\"Date\": \"ds\", \"Close\": \"y\"})\n",
    "        self.model.fit(df_prophet, freq=\"B\")\n",
    "        future = self.model.make_future_dataframe(df_prophet, periods=future_days)\n",
    "        forecast = self.model.predict(future)\n",
    "        return forecast[[\"ds\", \"yhat1\"]].tail(future_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Plotter:\n",
    "    @staticmethod\n",
    "    def plot_predictions(\n",
    "        history_dates, history_values, future_dates, gru_preds, prophet_preds\n",
    "    ):\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(history_dates, history_values, label=\"Historique\")\n",
    "        plt.plot(future_dates, gru_preds, label=\"GRU\", linestyle=\"--\")\n",
    "        plt.plot(future_dates, prophet_preds, label=\"NeuralProphet\", linestyle=\":\")\n",
    "        plt.title(\"PrÃ©vision du cours de l'action AMD\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Prix\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "WARNING - (py.warnings._showwarnmsg) - d:\\Personnels\\M2 Keyce\\ia\\scapping\\cc_rnn\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/gru_model.keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m gru_model = GRUPredictor(input_shape=(x_reshaped.shape[\u001b[32m1\u001b[39m], \u001b[32m1\u001b[39m))\n\u001b[32m     11\u001b[39m gru_model.train(x_reshaped, y)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mgru_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./models/gru_model.keras\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m last_sequence = x[-\u001b[32m1\u001b[39m]\n\u001b[32m     14\u001b[39m predictions_scaled = gru_model.predict_next_days(last_sequence, days=\u001b[32m21\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 70\u001b[39m, in \u001b[36mGRUPredictor.save\u001b[39m\u001b[34m(self, path)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave\u001b[39m(\u001b[38;5;28mself\u001b[39m, path=\u001b[33m\"\u001b[39m\u001b[33m./models/gru_model.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Personnels\\M2 Keyce\\ia\\scapping\\cc_rnn\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Personnels\\M2 Keyce\\ia\\scapping\\cc_rnn\\.venv\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:143\u001b[39m, in \u001b[36msave_model\u001b[39m\u001b[34m(model, filepath, weights_format, zipped)\u001b[39m\n\u001b[32m    141\u001b[39m         f.write(zip_filepath.getvalue())\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    144\u001b[39m         _save_model_to_fileobj(model, f, weights_format)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: './models/gru_model.keras'"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "loader = DataLoader()\n",
    "df = loader.fetch_data()\n",
    "\n",
    "pre = GRUPreprocessor()\n",
    "x, y, scaled = pre.transform(df)\n",
    "x_reshaped = pre.reshape_input(x)\n",
    "\n",
    "# GRU\n",
    "gru_model = GRUPredictor(input_shape=(x_reshaped.shape[1], 1))\n",
    "gru_model.train(x_reshaped, y)\n",
    "gru_model.save(\"../models/gru_model.keras\")\n",
    "last_sequence = x[-1]\n",
    "predictions_scaled = gru_model.predict_next_days(last_sequence, days=21)\n",
    "gru_predictions = pre.inverse_transform(predictions_scaled)\n",
    "\n",
    "# NeuralProphet\n",
    "prophet_model = NeuralProphetPredictor()\n",
    "prophet_result = prophet_model.train_predict(df, future_days=21)\n",
    "\n",
    "# Plot\n",
    "future_dates = pd.date_range(\n",
    "    start=df[\"Date\"].iloc[-1] + pd.Timedelta(days=1), periods=21, freq=\"B\"\n",
    ")\n",
    "Plotter.plot_predictions(\n",
    "    history_dates=df[\"Date\"],\n",
    "    history_values=df[\"Close\"],\n",
    "    future_dates=future_dates,\n",
    "    gru_preds=gru_predictions,\n",
    "    prophet_preds=prophet_result[\"yhat1\"].values,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
